{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Yoo_Paul_Final_Project</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Paul Yoo \n",
    "<br>\n",
    "Github Username: PKY-USCADS\n",
    "<br>\n",
    "USC ID: 9664-7785-73 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Importing Packages and Data "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T12:43:33.063627Z",
     "start_time": "2024-07-24T12:43:30.504716Z"
    }
   },
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Dropout, Conv1D, MaxPooling1D, LSTM\n",
    "from tensorflow.keras.optimizers import Adam"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T12:43:33.066189Z",
     "start_time": "2024-07-24T12:43:33.064500Z"
    }
   },
   "source": [
    "pos_dir = '../data/pos'\n",
    "neg_dir = '../data/neg'"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Data Exploration and Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i-ii) Binary encoding for sentiments and Data cleaning\n",
    "Removed punctuation and numbers from reviews"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T12:43:33.069182Z",
     "start_time": "2024-07-24T12:43:33.066797Z"
    }
   },
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.replace('\\n', '')\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.lower()\n",
    "\n",
    "def load_reviews(directory):\n",
    "    reviews = []\n",
    "    for filename in sorted(os.listdir(directory)):\n",
    "        with open(os.path.join(directory, filename), 'r', encoding='utf-8') as file:\n",
    "            review = file.read()\n",
    "            clean_review = clean_text(review)\n",
    "            reviews.append(clean_review)\n",
    "    return reviews"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T12:43:33.674590Z",
     "start_time": "2024-07-24T12:43:33.070280Z"
    }
   },
   "source": [
    "pos_reviews = load_reviews(pos_dir)\n",
    "neg_reviews = load_reviews(neg_dir)\n",
    "pos_reviews[0:5]\n",
    "neg_reviews[0:5]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['plot two teen couples go to a church party drink and then drive they get into an accident one of the guys dies but his girlfriend continues to see him in her life and has nightmares whats the deal watch the movie and sorta find out critique a mindfuck movie for the teen generation that touches on a very cool idea but presents it in a very bad package which is what makes this review an even harder one to write since i generally applaud films which attempt to break the mold mess with your head and such lost highway memento but there are good and bad ways of making all types of films and these folks just didnt snag this one correctly they seem to have taken this pretty neat concept but executed it terribly so what are the problems with the movie well its main problem is that its simply too jumbled it starts off normal but then downshifts into this fantasy world in which you as an audience member have no idea whats going on there are dreams there are characters coming back from the dead there are others who look like the dead there are strange apparitions there are disappearances there are a looooot of chase scenes there are tons of weird things that happen and most of it is simply not explained now i personally dont mind trying to unravel a film every now and then but when all it does is give me the same clue over and over again i get kind of fed up after a while which is this films biggest problem its obviously got this big secret to hide but it seems to want to hide it completely until its final five minutes and do they make things entertaining thrilling or even engaging in the meantime not really the sad part is that the arrow and i both dig on flicks like this so we actually figured most of it out by the halfway point so all of the strangeness after that did start to make a little bit of sense but it still didnt the make the film all that more entertaining i guess the bottom line with movies like this is that you should always make sure that the audience is into it even before they are given the secret password to enter your world of understanding i mean showing melissa sagemiller running away from visions for about minutes throughout the movie is just plain lazy okay we get it there are people chasing her and we dont know who they are do we really need to see it over and over again how about giving us different scenes offering further insight into all of the strangeness going down in the movie apparently the studio took this film away from its director and chopped it up themselves and it shows there mightve been a pretty decent teen mindfuck movie in here somewhere but i guess the suits decided that turning it into a music video with little edge would make more sense the actors are pretty good for the most part although wes bentley just seemed to be playing the exact same character that he did in american beauty only in a new neighborhood but my biggest kudos go out to sagemiller who holds her own throughout the entire film and actually has you feeling her characters unraveling overall the film doesnt stick because it doesnt entertain its confusing it rarely excites and it feels pretty redundant for most of its runtime despite a pretty cool ending and explanation to all of the craziness that came before it oh and by the way this is not a horror or teen slasher flick its just packaged to look that way because someone is apparently assuming that the genre is still hot with the kids it also wrapped production two years ago and has been sitting on the shelves ever since whatever skip it wheres joblo coming from a nightmare of elm street blair witch the crow the crow salvation lost highway memento the others stir of echoes ',\n",
       " 'the happy bastards quick movie review damn that yk bug its got a head start in this movie starring jamie lee curtis and another baldwin brother william this time in a story regarding a crew of a tugboat that comes across a deserted russian tech ship that has a strangeness to it when they kick the power back on little do they know the power within going for the gore and bringing on a few action sequences here and there virus still feels very empty like a movie going for all flash and no substance we dont know why the crew was really out in the middle of nowhere we dont know the origin of what took over the ship just that a big pink flashy thing hit the mir and of course we dont know why donald sutherland is stumbling around drunkenly throughout here its just hey lets chase these people around with some robots the acting is below average even from the likes of curtis youre more likely to get a kick out of her work in halloween h sutherland is wasted and baldwin well hes acting like a baldwin of course the real star here are stan winstons robot design some schnazzy cgi and the occasional good gore shot like picking into someones brain so if robots and body parts really turn you on heres your movie otherwise its pretty much a sunken ship of a movie ',\n",
       " 'it is movies like these that make a jaded movie viewer thankful for the invention of the timex indiglo watch based on the late s television show by the same name the mod squad tells the tale of three reformed criminals under the employ of the police to go undercover however things go wrong as evidence gets stolen and they are immediately under suspicion of course the ads make it seem like so much more quick cuts cool music claire danes nice hair and cute outfits car chases stuff blowing up and the like sounds like a cool movie does it not after the first fifteen minutes it quickly becomes apparent that it is not the mod squad is certainly a slick looking production complete with nice hair and costumes but that simply isnt enough the film is best described as a cross between an hourlong cop show and a music video both stretched out into the span of an hour and a half and with it comes every single clich it doesnt really matter that the film is based on a television show as most of the plot elements have been recycled from everything weve already seen the characters and acting is nothing spectacular sometimes even bordering on wooden claire danes and omar epps deliver their lines as if they are bored which really transfers onto the audience the only one to escape relatively unscathed is giovanni ribisi who plays the resident crazy man ultimately being the only thing worth watching unfortunately even hes not enough to save this convoluted mess as all the characters dont do much apart from occupying screen time with the young cast cool clothes nice hair and hip soundtrack it appears that the film is geared towards the teenage mindset despite an american r rating which the content does not justify the film is way too juvenile for the older mindset information on the characters is literally spoonfed to the audience would it be that hard to show us instead of telling us dialogue is poorly written and the plot is extremely predictable the way the film progresses you likely wont even care if the heroes are in any jeopardy because youll know they arent basing the show on a s television show that nobody remembers is of questionable wisdom especially when one considers the target audience and the fact that the number of memorable films based on television shows can be counted on one hand even one thats missing a finger or two the number of times that i checked my watch six is a clear indication that this film is not one of them it is clear that the film is nothing more than an attempt to cash in on the teenage spending dollar judging from the rash of really awful teenflicks that weve been seeing as of late avoid this film at all costs ',\n",
       " ' quest for camelot is warner bros first featurelength fullyanimated attempt to steal clout from disneys cartoon empire but the mouse has no reason to be worried the only other recent challenger to their throne was last falls promising if flawed th century fox production anastasia but disneys hercules with its lively cast and colorful palate had her beat handsdown when it came time to crown s best piece of animation this year its no contest as quest for camelot is pretty much dead on arrival even the magic kingdom at its most mediocre thatd be pocahontas for those of you keeping score isnt nearly as dull as this the story revolves around the adventures of freespirited kayley voiced by jessalyn gilsig the earlyteen daughter of a belated knight from king arthurs round table kayleys only dream is to follow in her fathers footsteps and she gets her chance when evil warlord ruber gary oldman an exround table membergonebad steals arthurs magical sword excalibur and accidentally loses it in a dangerous boobytrapped forest with the help of hunky blind timberlanddweller garrett carey elwes and a twoheaded dragon eric idle and don rickles thats always arguing with itself kayley just might be able to break the medieval sexist mold and prove her worth as a fighter on arthurs side quest for camelot is missing pure showmanship an essential element if its ever expected to climb to the high ranks of disney theres nothing here that differentiates quest from something youd see on any given saturday morning cartoon subpar animation instantly forgettable songs poorlyintegrated computerized footage compare kayley and garretts runin with the angry ogre to hercs battle with the hydra i rest my case even the characters stink none of them are remotely interesting so much that the film becomes a race to see which one can outbland the others in the end its a tie they all win that dragons comedy shtick is awfully cloying but at least it shows signs of a pulse at least fans of the earlys tgif television lineup will be thrilled to find jaleel urkel white and bronson balki pinchot sharing the same footage a few scenes are nicely realized though im at a loss to recall enough to be specific and the actors providing the voice talent are enthusiastic though most are paired up with singers who dont sound a thing like them for their big musical moments jane seymour and celine dion but one must strain through too much of this mess to find the good aside from the fact that children will probably be as bored watching this as adults quest for camelot s most grievous error is its complete lack of personality and personality we learn from this mess goes a very long way ',\n",
       " 'synopsis a mentally unstable man undergoing psychotherapy saves a boy from a potentially fatal accident and then falls in love with the boys mother a fledgling restauranteur unsuccessfully attempting to gain the womans favor he takes pictures of her and kills a number of people in his way comments stalked is yet another in a seemingly endless string of spurnedpsychosgettingtheirrevenge type movies which are a stable category in the s film industry both theatrical and directtovideo their proliferation may be due in part to the fact that theyre typically inexpensive to produce no special effects no big name stars and serve as vehicles to flash nudity allowing them to frequent latenight cable television stalked wavers slightly from the norm in one respect the psycho never actually has an affair on the contrary hes rejected rather quickly the psycho typically is an exlover exwife or exhusband other than that stalked is just another redundant entry doomed to collect dust on video shelves and viewed after midnight on cable stalked does not provide much suspense though that is what it sets out to do interspersed throughout the opening credits for instance a serioussounding narrator spouts statistics about stalkers and ponders what may cause a man to stalk its implicitly implied that all stalkers are men while pictures of a boy are shown on the screen after these credits a snapshot of actor jay underwood appears the narrator states that this is the story of daryl gleason and tells the audience that he is the stalker of course really this is the story of restauranteur brooke daniels if the movie was meant to be about daryl then it should have been called stalker not stalked okay so we know who the stalker is even before the movie starts no guesswork required stalked proceeds then as it begins obvious obvious obvious the opening sequence contrived quite a bit brings daryl and brooke the victim together daryl obsesses over brooke follows her around and tries to woo her ultimately rejected by her his plans become more and more desperate and elaborate these plans include the alltime psychoinlove cliche the murdered pet for some reason this genres films require a dead pet to be found by the victim stalked stalked is no exception its a cat this time found in the shower events like these lead to the inevitable showdown between stalker and stalked where only one survives guess who it invariably always is and youll guess the conclusion to this turkey stalkeds cast is uniformly adequate not anything to write home about but also not all that bad either jay underwood as the stalker turns toward melodrama a bit too much he overdoes it in other words but he still manages to be creepy enough to pass as the type of stalker the story demands maryam dabo about the only actor close to being a star here she played the bond chick in the living daylights is equally adequate as the stalked of the title even though she seems too ditzy at times to be a strong independent businessowner brooke dabo needs to be ditzy however for the plot to proceed toward the end for example brooke has her suspicions about daryl to ensure he wont use it as another excuse to see her brooke decides to return a toolbox he had left at her place to his house does she just leave the toolbox at the door when no one answers of course not she tries the door opens it and wanders around the house when daryl returns he enters the house of course so our heroine is in danger somehow even though her car is parked at the front of the house right by the front door daryl is oblivious to her presence inside the whole episode places an incredible strain on the audiences suspension of disbelief and questions the validity of either characters intelligence stalked receives two stars because even though it is highly derivative and somewhat boring it is not so bad that it cannot be watched rated r mostly for several murder scenes and brief nudity in a strip bar it is not as offensive as many other thrillers in this genre are if youre in the mood for a good suspense film though stake out something else ']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T12:43:33.676882Z",
     "start_time": "2024-07-24T12:43:33.675182Z"
    }
   },
   "source": [
    "reviews = pos_reviews + neg_reviews\n",
    "labels = [1] * len(pos_reviews) + [0] * len(neg_reviews)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### (iii) Split train and test sets."
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T12:43:33.679098Z",
     "start_time": "2024-07-24T12:43:33.677533Z"
    }
   },
   "source": [
    "pos_train = pos_reviews[:700]\n",
    "neg_train = neg_reviews[:700]\n",
    "pos_test = pos_reviews[700:]\n",
    "neg_test = neg_reviews[700:]"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T12:43:33.681247Z",
     "start_time": "2024-07-24T12:43:33.679680Z"
    }
   },
   "source": [
    "reviews_train = pos_train + neg_train\n",
    "labels_train = [1] * 700 + [0] * 700\n",
    "reviews_test = pos_test + neg_test\n",
    "labels_test = [1] * 300 + [0] * 300"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T12:43:33.683149Z",
     "start_time": "2024-07-24T12:43:33.681750Z"
    }
   },
   "source": [
    "labels_train = np.array(labels_train)\n",
    "labels_test = np.array(labels_test)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### iv. Unique words"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T12:43:33.770596Z",
     "start_time": "2024-07-24T12:43:33.683713Z"
    }
   },
   "source": [
    "words = ''.join(reviews)\n",
    "unique_words = len(set(words.split()))\n",
    "unique_words"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47037"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### v. Review Length"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T12:43:33.808377Z",
     "start_time": "2024-07-24T12:43:33.772492Z"
    }
   },
   "source": [
    "review_length = [len(review.split()) for review in reviews]\n",
    "avg_review_length = np.mean(review_length)\n",
    "std_review_length = np.std(review_length)\n",
    "print(avg_review_length)\n",
    "print(std_review_length)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "644.3575\n",
      "284.98012333099655\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### vi. Review Length Histogram"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T12:43:33.951288Z",
     "start_time": "2024-07-24T12:43:33.809227Z"
    }
   },
   "source": [
    "plt.hist(review_length, bins=250, color='blue', alpha=0.7)\n",
    "plt.title('Review Length Histogram', fontsize=22, fontweight='bold')\n",
    "plt.xlabel('Review Length', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Frequency', fontsize=12, fontweight='bold')\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### vii. Tokenization"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<font color='Cyan'>\n",
    "\n",
    "Reference [1] for Tokenizer <br>\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer <br>\n",
    " <br>\n",
    "Reference [2] for pad_sequences <br>\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences <br>\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T12:43:34.465800Z",
     "start_time": "2024-07-24T12:43:33.952042Z"
    }
   },
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(reviews_train + reviews_test)\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(reviews_train)\n",
    "test_sequences = tokenizer.texts_to_sequences(reviews_test)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### viii. Select Reviews that have length below 70%: L"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T12:43:34.468939Z",
     "start_time": "2024-07-24T12:43:34.466498Z"
    }
   },
   "source": [
    "L_70 = np.percentile(review_length, 70)\n",
    "L = int(L_70)\n",
    "print(L_70)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "737.0\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### ix.Truncate Reviews longer than L words and zero-pad reviews shorter than L\n"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T12:43:34.498987Z",
     "start_time": "2024-07-24T12:43:34.469475Z"
    }
   },
   "source": [
    "seq_pad_train = pad_sequences(train_sequences, maxlen=L, padding='post', truncating='post')\n",
    "seq_pad_test = pad_sequences(test_sequences, maxlen=L, padding='post', truncating='post')"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T12:43:34.501444Z",
     "start_time": "2024-07-24T12:43:34.499661Z"
    }
   },
   "source": [
    "print(seq_pad_train.shape)\n",
    "print(seq_pad_test.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 737)\n",
      "(600, 737)\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### i. Embedding"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<font color='Cyan'>\n",
    "\n",
    "Reference [3] for Sequential <br>\n",
    "from tensorflow.keras.models import Sequential <br>\n",
    " <br>\n",
    "Reference [4] for Input <br>\n",
    "from tensorflow.keras.layers import Input <br>\n",
    " <br>\n",
    "Reference [5] for Embedding <br>\n",
    "from tensorflow.keras.layers import Embedding <br>\n",
    " <br>\n",
    "Reference [6] for Flatten <br>\n",
    "from tensorflow.keras.layers import Flatten <br>\n",
    " <br>\n",
    "Reference [7] for Keras Text Classifaction <br>\n",
    "https://realpython.com/python-keras-text-classification/ <br>\n",
    " <br>\n",
    "Reference [8] for Keras Embedding Layer <br>\n",
    "https://www.kaggle.com/code/rajmehra03/a-detailed-explanation-of-keras-embedding-layer <br>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T12:43:34.503505Z",
     "start_time": "2024-07-24T12:43:34.502108Z"
    }
   },
   "source": [
    "vocab_size = 5000\n",
    "embedding_dim = 32"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T12:43:34.519313Z",
     "start_time": "2024-07-24T12:43:34.504042Z"
    }
   },
   "source": [
    "model_embedding = Sequential([\n",
    "    Input(shape=(L,)),\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, name='embedding'),\n",
    "    Flatten(),\n",
    "])"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T12:43:34.525156Z",
     "start_time": "2024-07-24T12:43:34.519818Z"
    }
   },
   "source": [
    "print(model_embedding.summary())"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001B[38;5;33mEmbedding\u001B[0m)           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m737\u001B[0m, \u001B[38;5;34m32\u001B[0m)        │       \u001B[38;5;34m160,000\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001B[38;5;33mFlatten\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m23584\u001B[0m)          │             \u001B[38;5;34m0\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">737</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">160,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23584</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m160,000\u001B[0m (625.00 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">160,000</span> (625.00 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m160,000\u001B[0m (625.00 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">160,000</span> (625.00 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T12:43:34.756832Z",
     "start_time": "2024-07-24T12:43:34.525619Z"
    }
   },
   "source": [
    "train_embeddings = model_embedding.predict(seq_pad_train)\n",
    "test_embeddings = model_embedding.predict(seq_pad_test)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m44/44\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 577us/step\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T12:43:34.759435Z",
     "start_time": "2024-07-24T12:43:34.757611Z"
    }
   },
   "source": [
    "print(train_embeddings.shape)\n",
    "print(test_embeddings.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 23584)\n",
      "(600, 23584)\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T12:43:34.763612Z",
     "start_time": "2024-07-24T12:43:34.760504Z"
    }
   },
   "source": [
    "weights_embedding = model_embedding.get_layer('embedding').get_weights()"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T12:43:34.767024Z",
     "start_time": "2024-07-24T12:43:34.764389Z"
    }
   },
   "source": [
    "weights_embedding"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.02380102, -0.01036191, -0.01337112, ..., -0.00537016,\n",
       "         -0.00760038, -0.04689744],\n",
       "        [-0.01443589,  0.00757673, -0.0479769 , ...,  0.01814722,\n",
       "         -0.04701132,  0.00215247],\n",
       "        [ 0.02630151, -0.03847845,  0.00986178, ...,  0.02729886,\n",
       "          0.00781105,  0.01136418],\n",
       "        ...,\n",
       "        [-0.02988317,  0.04945249, -0.0326362 , ...,  0.0376276 ,\n",
       "          0.04628843, -0.00503528],\n",
       "        [-0.03081195,  0.02328899, -0.01434474, ...,  0.02242369,\n",
       "          0.00229847,  0.03645339],\n",
       "        [ 0.03301283,  0.0037114 ,  0.00293043, ..., -0.03209348,\n",
       "         -0.04480059, -0.007946  ]], dtype=float32)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i. Train MLP\n",
    "The guideline asks to use epochs = 2, batch_size = 10, but I tried extra combination to find optimal epochs and batch size with better validation accuracy. "
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<font color='Cyan'>\n",
    "\n",
    "Reference [9] for Dense <br>\n",
    "from tensorflow.keras.layers import Dense <br>\n",
    " <br>\n",
    "Reference [10] for Dropout <br>\n",
    "from tensorflow.keras.layers import Dropout <br>\n",
    " <br>\n",
    "Reference [11] for Machine Learning Mastery MLP Neural Network Model <br>\n",
    "https://machinelearningmastery.com/build-multi-layer-perceptron-neural-network-models-keras/ <br>\n",
    " <br>\n",
    "Reference [12] for DataCamp Concept of MLP in Machine Learning <br>\n",
    "https://www.datacamp.com/tutorial/multilayer-perceptrons-in-machine-learning <br>\n",
    " <br>\n",
    "Reference [13] for Towards Data Science for article reference <br>\n",
    "https://towardsdatascience.com/multilayer-perceptron-explained-with-a-real-life-example-and-python-code-sentiment-analysis-cb408ee93141 <br>\n",
    " <br>\n",
    "Reference [14] for ScienceDirect <br>\n",
    "https://www.sciencedirect.com/topics/computer-science/multilayer-perceptron <br>\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T12:43:34.786407Z",
     "start_time": "2024-07-24T12:43:34.767598Z"
    }
   },
   "source": [
    "mlp_model = Sequential([\n",
    "    Input(shape=(L,)),\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, name='mlp_embedding'),\n",
    "    Flatten(),\n",
    "    Dense(50, activation='relu', name='mlp_relu1'),\n",
    "    Dropout(0.2),\n",
    "    Dense(50, activation='relu', name='mlp_relu2'),\n",
    "    Dropout(0.5),\n",
    "    Dense(50, activation='relu', name='mlp_relu3'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid', name='mlp_sigmoid')\n",
    "])"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T12:43:34.791626Z",
     "start_time": "2024-07-24T12:43:34.787139Z"
    }
   },
   "source": [
    "mlp_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T12:43:34.798313Z",
     "start_time": "2024-07-24T12:43:34.792177Z"
    }
   },
   "source": [
    "mlp_model.summary()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_1\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ mlp_embedding (\u001B[38;5;33mEmbedding\u001B[0m)       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m737\u001B[0m, \u001B[38;5;34m32\u001B[0m)        │       \u001B[38;5;34m160,000\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001B[38;5;33mFlatten\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m23584\u001B[0m)          │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ mlp_relu1 (\u001B[38;5;33mDense\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m50\u001B[0m)             │     \u001B[38;5;34m1,179,250\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001B[38;5;33mDropout\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m50\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ mlp_relu2 (\u001B[38;5;33mDense\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m50\u001B[0m)             │         \u001B[38;5;34m2,550\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m50\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ mlp_relu3 (\u001B[38;5;33mDense\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m50\u001B[0m)             │         \u001B[38;5;34m2,550\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m50\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ mlp_sigmoid (\u001B[38;5;33mDense\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │            \u001B[38;5;34m51\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ mlp_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">737</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">160,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23584</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ mlp_relu1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,250</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ mlp_relu2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,550</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ mlp_relu3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,550</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ mlp_sigmoid (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m1,344,401\u001B[0m (5.13 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,344,401</span> (5.13 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m1,344,401\u001B[0m (5.13 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,344,401</span> (5.13 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T12:43:34.800668Z",
     "start_time": "2024-07-24T12:43:34.798874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mlp_epochs_list = [2, 5, 10]\n",
    "mlp_batch_sizes = [10, 20, 30]\n",
    "\n",
    "mlp_original_accuracy = 0\n",
    "mlp_original_loss = 0\n",
    "mlp_original_val_loss =0\n",
    "mlp_original_val_accuracy = 0\n",
    "\n",
    "mlp_best_accuracy = 0\n",
    "mlp_best_loss = 0\n",
    "mlp_best_val_loss =0\n",
    "mlp_best_val_accuracy = 0\n",
    "\n",
    "mlp_best_epoch = 0\n",
    "mlp_best_batch_size = 0\n",
    "mlp_best_history = None"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T12:44:03.246182Z",
     "start_time": "2024-07-24T12:43:34.801252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epochs in mlp_epochs_list:\n",
    "    for batch_size in mlp_batch_sizes:\n",
    "        print(\"\")\n",
    "        print(f\"Training with epochs = {epochs} and batch size = {batch_size}\")\n",
    "        print(\"\")\n",
    "        mlp_history = mlp_model.fit(seq_pad_train, labels_train, epochs=epochs, batch_size=batch_size, validation_data=(seq_pad_test, labels_test), verbose=1)\n",
    "        \n",
    "        accuracy = max(mlp_history.history['accuracy'])\n",
    "        loss = max(mlp_history.history['loss'])        \n",
    "        val_accuracy = max(mlp_history.history['val_accuracy'])\n",
    "        val_loss = max(mlp_history.history['val_loss'])\n",
    "        \n",
    "        if epochs == 2 and batch_size == 10:\n",
    "            mlp_original_accuracy = accuracy\n",
    "            mlp_original_loss = loss\n",
    "            mlp_original_val_accuracy = val_accuracy\n",
    "            mlp_original_val_loss = val_loss\n",
    "        \n",
    "        if val_accuracy > mlp_best_val_accuracy:\n",
    "            mlp_best_accuracy = accuracy\n",
    "            mlp_best_loss = loss\n",
    "            mlp_best_val_loss = val_loss\n",
    "            mlp_best_val_accuracy = val_accuracy\n",
    "            mlp_best_epoch = epochs\n",
    "            mlp_best_batch_size = batch_size\n",
    "            mlp_best_history = mlp_history"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with epochs = 2 and batch size = 10\n",
      "\n",
      "Epoch 1/2\n",
      "\u001B[1m140/140\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.4981 - loss: 0.6963 - val_accuracy: 0.5133 - val_loss: 0.6906\n",
      "Epoch 2/2\n",
      "\u001B[1m140/140\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.5893 - loss: 0.6713 - val_accuracy: 0.6133 - val_loss: 0.6625\n",
      "\n",
      "Training with epochs = 2 and batch size = 20\n",
      "\n",
      "Epoch 1/2\n",
      "\u001B[1m70/70\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8461 - loss: 0.4149 - val_accuracy: 0.6017 - val_loss: 0.7404\n",
      "Epoch 2/2\n",
      "\u001B[1m70/70\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9695 - loss: 0.1280 - val_accuracy: 0.6050 - val_loss: 1.0131\n",
      "\n",
      "Training with epochs = 2 and batch size = 30\n",
      "\n",
      "Epoch 1/2\n",
      "\u001B[1m47/47\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9965 - loss: 0.0268 - val_accuracy: 0.6050 - val_loss: 1.2694\n",
      "Epoch 2/2\n",
      "\u001B[1m47/47\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9934 - loss: 0.0212 - val_accuracy: 0.6200 - val_loss: 1.3266\n",
      "\n",
      "Training with epochs = 5 and batch size = 10\n",
      "\n",
      "Epoch 1/5\n",
      "\u001B[1m140/140\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9952 - loss: 0.0143 - val_accuracy: 0.6067 - val_loss: 1.8821\n",
      "Epoch 2/5\n",
      "\u001B[1m140/140\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9961 - loss: 0.0103 - val_accuracy: 0.5983 - val_loss: 1.7574\n",
      "Epoch 3/5\n",
      "\u001B[1m140/140\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.6050 - val_loss: 2.4336\n",
      "Epoch 4/5\n",
      "\u001B[1m140/140\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9967 - loss: 0.0091 - val_accuracy: 0.5667 - val_loss: 2.6134\n",
      "Epoch 5/5\n",
      "\u001B[1m140/140\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9982 - loss: 0.0061 - val_accuracy: 0.5750 - val_loss: 2.4351\n",
      "\n",
      "Training with epochs = 5 and batch size = 20\n",
      "\n",
      "Epoch 1/5\n",
      "\u001B[1m70/70\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.9986 - loss: 0.0057 - val_accuracy: 0.5867 - val_loss: 2.3986\n",
      "Epoch 2/5\n",
      "\u001B[1m70/70\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.5750 - val_loss: 2.5484\n",
      "Epoch 3/5\n",
      "\u001B[1m70/70\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.9977 - loss: 0.0036 - val_accuracy: 0.5750 - val_loss: 2.7095\n",
      "Epoch 4/5\n",
      "\u001B[1m70/70\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.5750 - val_loss: 2.7323\n",
      "Epoch 5/5\n",
      "\u001B[1m70/70\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 7.1763e-04 - val_accuracy: 0.5750 - val_loss: 2.8634\n",
      "\n",
      "Training with epochs = 5 and batch size = 30\n",
      "\n",
      "Epoch 1/5\n",
      "\u001B[1m47/47\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 1.0000 - loss: 4.9565e-04 - val_accuracy: 0.5767 - val_loss: 2.9206\n",
      "Epoch 2/5\n",
      "\u001B[1m47/47\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 6.7137e-04 - val_accuracy: 0.5733 - val_loss: 2.9948\n",
      "Epoch 3/5\n",
      "\u001B[1m47/47\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 3.0903e-04 - val_accuracy: 0.5750 - val_loss: 3.0406\n",
      "Epoch 4/5\n",
      "\u001B[1m47/47\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 1.0000 - loss: 2.2939e-04 - val_accuracy: 0.5750 - val_loss: 3.0830\n",
      "Epoch 5/5\n",
      "\u001B[1m47/47\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 1.0000 - loss: 8.3820e-04 - val_accuracy: 0.5733 - val_loss: 3.1885\n",
      "\n",
      "Training with epochs = 10 and batch size = 10\n",
      "\n",
      "Epoch 1/10\n",
      "\u001B[1m140/140\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 4.3854e-04 - val_accuracy: 0.5783 - val_loss: 3.4733\n",
      "Epoch 2/10\n",
      "\u001B[1m140/140\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 6.4107e-05 - val_accuracy: 0.5783 - val_loss: 3.5410\n",
      "Epoch 3/10\n",
      "\u001B[1m140/140\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 3.8047e-05 - val_accuracy: 0.5833 - val_loss: 3.6072\n",
      "Epoch 4/10\n",
      "\u001B[1m140/140\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 1.4221e-04 - val_accuracy: 0.5900 - val_loss: 3.7517\n",
      "Epoch 5/10\n",
      "\u001B[1m140/140\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 1.5118e-04 - val_accuracy: 0.5883 - val_loss: 3.8222\n",
      "Epoch 6/10\n",
      "\u001B[1m140/140\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 5.6702e-05 - val_accuracy: 0.5867 - val_loss: 3.9182\n",
      "Epoch 7/10\n",
      "\u001B[1m140/140\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 1.2797e-04 - val_accuracy: 0.5933 - val_loss: 4.0564\n",
      "Epoch 8/10\n",
      "\u001B[1m140/140\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 1.8154e-04 - val_accuracy: 0.5950 - val_loss: 4.1858\n",
      "Epoch 9/10\n",
      "\u001B[1m140/140\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 1.3545e-04 - val_accuracy: 0.5967 - val_loss: 4.4610\n",
      "Epoch 10/10\n",
      "\u001B[1m140/140\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 8.2240e-05 - val_accuracy: 0.6017 - val_loss: 4.4246\n",
      "\n",
      "Training with epochs = 10 and batch size = 20\n",
      "\n",
      "Epoch 1/10\n",
      "\u001B[1m70/70\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 4.7280e-05 - val_accuracy: 0.5967 - val_loss: 4.3738\n",
      "Epoch 2/10\n",
      "\u001B[1m70/70\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 5.2677e-05 - val_accuracy: 0.5950 - val_loss: 4.4165\n",
      "Epoch 3/10\n",
      "\u001B[1m70/70\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 8.5927e-05 - val_accuracy: 0.6117 - val_loss: 4.4155\n",
      "Epoch 4/10\n",
      "\u001B[1m70/70\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 1.0000 - loss: 9.8599e-06 - val_accuracy: 0.6100 - val_loss: 4.3959\n",
      "Epoch 5/10\n",
      "\u001B[1m70/70\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9943 - loss: 0.0317 - val_accuracy: 0.5467 - val_loss: 3.4090\n",
      "Epoch 6/10\n",
      "\u001B[1m70/70\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9724 - loss: 0.1202 - val_accuracy: 0.5633 - val_loss: 2.3184\n",
      "Epoch 7/10\n",
      "\u001B[1m70/70\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9999 - loss: 0.0032 - val_accuracy: 0.5850 - val_loss: 2.1110\n",
      "Epoch 8/10\n",
      "\u001B[1m70/70\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.5767 - val_loss: 2.5084\n",
      "Epoch 9/10\n",
      "\u001B[1m70/70\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 7.2495e-04 - val_accuracy: 0.5850 - val_loss: 2.5593\n",
      "Epoch 10/10\n",
      "\u001B[1m70/70\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 8.6090e-04 - val_accuracy: 0.5817 - val_loss: 2.7179\n",
      "\n",
      "Training with epochs = 10 and batch size = 30\n",
      "\n",
      "Epoch 1/10\n",
      "\u001B[1m47/47\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 1.0000 - loss: 3.3883e-04 - val_accuracy: 0.5867 - val_loss: 2.8451\n",
      "Epoch 2/10\n",
      "\u001B[1m47/47\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 1.0000 - loss: 6.3602e-04 - val_accuracy: 0.5667 - val_loss: 3.1333\n",
      "Epoch 3/10\n",
      "\u001B[1m47/47\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 1.0000 - loss: 5.5799e-04 - val_accuracy: 0.5633 - val_loss: 3.2314\n",
      "Epoch 4/10\n",
      "\u001B[1m47/47\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 1.0000 - loss: 3.0576e-04 - val_accuracy: 0.5667 - val_loss: 3.3061\n",
      "Epoch 5/10\n",
      "\u001B[1m47/47\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9994 - loss: 7.4615e-04 - val_accuracy: 0.5800 - val_loss: 2.6310\n",
      "Epoch 6/10\n",
      "\u001B[1m47/47\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.5800 - val_loss: 2.7779\n",
      "Epoch 7/10\n",
      "\u001B[1m47/47\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 7.3312e-04 - val_accuracy: 0.5800 - val_loss: 2.9790\n",
      "Epoch 8/10\n",
      "\u001B[1m47/47\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 3.4546e-04 - val_accuracy: 0.5767 - val_loss: 3.1356\n",
      "Epoch 9/10\n",
      "\u001B[1m47/47\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 7.9301e-04 - val_accuracy: 0.5750 - val_loss: 3.3810\n",
      "Epoch 10/10\n",
      "\u001B[1m47/47\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 1.0000 - loss: 1.8210e-04 - val_accuracy: 0.5717 - val_loss: 3.5092\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. Train and Test Accuracies\n",
    "\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T12:44:03.252403Z",
     "start_time": "2024-07-24T12:44:03.250129Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Best validation accuracy: {mlp_best_val_accuracy:.4f} when epochs = {mlp_best_epoch} and batch size = {mlp_best_batch_size}\")\n",
    "print(f\"with training accuracy: {mlp_best_accuracy:.4f}, training loss: {mlp_best_loss:.8f}, and validation loss: {mlp_best_val_loss:.4f}\")\n",
    "print(\"\")\n",
    "print(f\"When epochs = 2 and batch size = 10, validation accuracy: {mlp_original_val_accuracy:.4f}\")\n",
    "print(f\"with training accuracy: {mlp_original_accuracy:.4f}, training loss: {mlp_original_loss:.8f}, and validation loss: {mlp_original_val_loss:.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation accuracy: 0.6200 when epochs = 2 and batch size = 30\n",
      "with training accuracy: 0.9979, training loss: 0.02190609, and validation loss: 1.3266\n",
      "\n",
      "When epochs = 2 and batch size = 10, validation accuracy: 0.6133\n",
      "with training accuracy: 0.6071, training loss: 0.69486505, and validation loss: 0.6906\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T12:44:03.257383Z",
     "start_time": "2024-07-24T12:44:03.253205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if mlp_best_val_accuracy > mlp_original_val_accuracy:\n",
    "    print(f\"When comparing, the project guideline tells to use epochs = 2 and batch size = 10, but from the model training, it shows that using epochs = {mlp_best_epoch} and batch size = {mlp_best_batch_size} gives better fitted model for the classification. However, since this model has higher validation loss, which indicates potential overfit issue leading to further tuning for reduction of overfitting.\")\n",
    "else:\n",
    "    print(\"It shows that using epoch = 2 and batch size = 10 as project guideline directed returns the highest validation accuracy, which means the best fitted model for classification.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When comparing, the project guideline tells to use epochs = 2 and batch size = 10, but from the model training, it shows that using epochs = 2 and batch size = 30 gives better fitted model for the classification. However, since this model has higher validation loss, which indicates potential overfit issue leading to further tuning for reduction of overfitting.\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### (e) One-Dimensional Convolutional Neural Network"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### i. train convolutional neural network model\n",
    "The guideline asks to use epochs = 2, batch_size = 10 same as MLP model, but I tried extra combination to find optimal epochs and batch size with better validation accuracy. "
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<font color='Cyan'>\n",
    "\n",
    "Reference [15] for Conv1D <br>\n",
    "from tensorflow.keras.layers import Conv1D <br>\n",
    " <br>\n",
    "Reference [16] for MaxPooling1D <br>\n",
    "from tensorflow.keras.layers import MaxPooling1D <br>\n",
    " <br>\n",
    "Reference [17] for GeeksforGeeks Concept of Convolutional Neural Network <br>\n",
    "https://www.geeksforgeeks.org/what-is-a-1d-convolutional-layer-in-deep-learning/ <br>\n",
    " <br>\n",
    "Reference [18] for ScienceDirect for article reference <br>\n",
    "https://www.sciencedirect.com/science/article/pii/S0888327020307846 <br>\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T12:44:03.284234Z",
     "start_time": "2024-07-24T12:44:03.258016Z"
    }
   },
   "source": [
    "cnn_model = Sequential([\n",
    "    Input(shape=(L,)),\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, name='cnn_embedding'),\n",
    "    Conv1D(32, 3, activation='relu', name='cnn_Cov1D'),\n",
    "    MaxPooling1D(pool_size=2, strides=2),\n",
    "    Flatten(),\n",
    "    Dense(50, activation='relu', name='cnn_relu1'),\n",
    "    Dropout(0.2),\n",
    "    Dense(50, activation='relu', name='cnn_relu2'),\n",
    "    Dropout(0.5),\n",
    "    Dense(50, activation='relu', name='cnn_relu3'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid', name='cnn_sigmoid')\n",
    "])"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T12:44:03.288019Z",
     "start_time": "2024-07-24T12:44:03.284911Z"
    }
   },
   "source": [
    "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T12:44:03.294860Z",
     "start_time": "2024-07-24T12:44:03.288506Z"
    }
   },
   "source": [
    "cnn_model.summary()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_2\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ cnn_embedding (\u001B[38;5;33mEmbedding\u001B[0m)       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m737\u001B[0m, \u001B[38;5;34m32\u001B[0m)        │       \u001B[38;5;34m160,000\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ cnn_Cov1D (\u001B[38;5;33mConv1D\u001B[0m)              │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m735\u001B[0m, \u001B[38;5;34m32\u001B[0m)        │         \u001B[38;5;34m3,104\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001B[38;5;33mMaxPooling1D\u001B[0m)    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m367\u001B[0m, \u001B[38;5;34m32\u001B[0m)        │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (\u001B[38;5;33mFlatten\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m11744\u001B[0m)          │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ cnn_relu1 (\u001B[38;5;33mDense\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m50\u001B[0m)             │       \u001B[38;5;34m587,250\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m50\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ cnn_relu2 (\u001B[38;5;33mDense\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m50\u001B[0m)             │         \u001B[38;5;34m2,550\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m50\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ cnn_relu3 (\u001B[38;5;33mDense\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m50\u001B[0m)             │         \u001B[38;5;34m2,550\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m50\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ cnn_sigmoid (\u001B[38;5;33mDense\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │            \u001B[38;5;34m51\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ cnn_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">737</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">160,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ cnn_Cov1D (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">735</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,104</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">367</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11744</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ cnn_relu1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">587,250</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ cnn_relu2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,550</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ cnn_relu3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,550</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ cnn_sigmoid (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m755,505\u001B[0m (2.88 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">755,505</span> (2.88 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m755,505\u001B[0m (2.88 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">755,505</span> (2.88 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T12:44:03.297439Z",
     "start_time": "2024-07-24T12:44:03.295485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cnn_epochs_list = [2, 5, 10]\n",
    "cnn_batch_sizes = [10, 20, 30]\n",
    "\n",
    "cnn_original_accuracy = 0\n",
    "cnn_original_loss = 0\n",
    "cnn_original_val_loss =0\n",
    "cnn_original_val_accuracy = 0\n",
    "\n",
    "cnn_best_accuracy = 0\n",
    "cnn_best_loss = 0\n",
    "cnn_best_val_loss =0\n",
    "cnn_best_val_accuracy = 0\n",
    "\n",
    "cnn_best_epoch = 0\n",
    "cnn_best_batch_size = 0\n",
    "cnn_best_history = None"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T12:44:38.191369Z",
     "start_time": "2024-07-24T12:44:03.297905Z"
    }
   },
   "source": [
    "for epochs in cnn_epochs_list:\n",
    "    for batch_size in cnn_batch_sizes:\n",
    "        print(\"\")\n",
    "        print(f\"Training with epochs = {epochs} and batch size = {batch_size}\")\n",
    "        print(\"\")\n",
    "        cnn_history = cnn_model.fit(seq_pad_train, labels_train, epochs=epochs, batch_size=batch_size, validation_data=(seq_pad_test, labels_test), verbose=1)\n",
    "        \n",
    "        accuracy = max(cnn_history.history['accuracy'])\n",
    "        loss = max(cnn_history.history['loss'])        \n",
    "        val_accuracy = max(cnn_history.history['val_accuracy'])\n",
    "        val_loss = max(cnn_history.history['val_loss'])\n",
    "        \n",
    "        if epochs == 2 and batch_size == 10:\n",
    "            cnn_original_accuracy = accuracy\n",
    "            cnn_original_loss = loss\n",
    "            cnn_original_val_accuracy = val_accuracy\n",
    "            cnn_original_val_loss = val_loss\n",
    "        \n",
    "        if val_accuracy > cnn_best_val_accuracy:\n",
    "            cnn_best_accuracy = accuracy\n",
    "            cnn_best_loss = loss\n",
    "            cnn_best_val_loss = val_loss\n",
    "            cnn_best_val_accuracy = val_accuracy\n",
    "            cnn_best_epoch = epochs\n",
    "            cnn_best_batch_size = batch_size\n",
    "            cnn_best_history = cnn_history"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with epochs = 2 and batch size = 10\n",
      "\n",
      "Epoch 1/2\n",
      "\u001B[1m140/140\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.4929 - loss: 0.7081 - val_accuracy: 0.5000 - val_loss: 0.6925\n",
      "Epoch 2/2\n",
      "\u001B[1m140/140\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.5107 - loss: 0.6918 - val_accuracy: 0.5517 - val_loss: 0.6903\n",
      "\n",
      "Training with epochs = 2 and batch size = 20\n",
      "\n",
      "Epoch 1/2\n",
      "\u001B[1m70/70\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.5891 - loss: 0.6774 - val_accuracy: 0.5817 - val_loss: 0.6802\n",
      "Epoch 2/2\n",
      "\u001B[1m70/70\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.7096 - loss: 0.6263 - val_accuracy: 0.6917 - val_loss: 0.6315\n",
      "\n",
      "Training with epochs = 2 and batch size = 30\n",
      "\n",
      "Epoch 1/2\n",
      "\u001B[1m47/47\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.8835 - loss: 0.4474 - val_accuracy: 0.6100 - val_loss: 0.7723\n",
      "Epoch 2/2\n",
      "\u001B[1m47/47\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9404 - loss: 0.3044 - val_accuracy: 0.7267 - val_loss: 0.6943\n",
      "\n",
      "Training with epochs = 5 and batch size = 10\n",
      "\n",
      "Epoch 1/5\n",
      "\u001B[1m140/140\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.9669 - loss: 0.1512 - val_accuracy: 0.7050 - val_loss: 1.2044\n",
      "Epoch 2/5\n",
      "\u001B[1m140/140\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.9644 - loss: 0.1298 - val_accuracy: 0.7183 - val_loss: 0.8394\n",
      "Epoch 3/5\n",
      "\u001B[1m140/140\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.9815 - loss: 0.0781 - val_accuracy: 0.7183 - val_loss: 0.9296\n",
      "Epoch 4/5\n",
      "\u001B[1m140/140\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9815 - loss: 0.0936 - val_accuracy: 0.7250 - val_loss: 0.9722\n",
      "Epoch 5/5\n",
      "\u001B[1m140/140\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9808 - loss: 0.0782 - val_accuracy: 0.7400 - val_loss: 1.0315\n",
      "\n",
      "Training with epochs = 5 and batch size = 20\n",
      "\n",
      "Epoch 1/5\n",
      "\u001B[1m70/70\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9909 - loss: 0.0561 - val_accuracy: 0.7400 - val_loss: 1.0545\n",
      "Epoch 2/5\n",
      "\u001B[1m70/70\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9899 - loss: 0.0504 - val_accuracy: 0.6933 - val_loss: 1.7808\n",
      "Epoch 3/5\n",
      "\u001B[1m70/70\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9879 - loss: 0.0440 - val_accuracy: 0.7200 - val_loss: 1.6375\n",
      "Epoch 4/5\n",
      "\u001B[1m70/70\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.9967 - loss: 0.0266 - val_accuracy: 0.7567 - val_loss: 1.1847\n",
      "Epoch 5/5\n",
      "\u001B[1m70/70\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9963 - loss: 0.0387 - val_accuracy: 0.7033 - val_loss: 1.9220\n",
      "\n",
      "Training with epochs = 5 and batch size = 30\n",
      "\n",
      "Epoch 1/5\n",
      "\u001B[1m47/47\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.9934 - loss: 0.0337 - val_accuracy: 0.7450 - val_loss: 1.3558\n",
      "Epoch 2/5\n",
      "\u001B[1m47/47\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - accuracy: 0.9968 - loss: 0.0200 - val_accuracy: 0.7433 - val_loss: 1.2592\n",
      "Epoch 3/5\n",
      "\u001B[1m47/47\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.9986 - loss: 0.0146 - val_accuracy: 0.7250 - val_loss: 1.6026\n",
      "Epoch 4/5\n",
      "\u001B[1m47/47\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9954 - loss: 0.0382 - val_accuracy: 0.7383 - val_loss: 1.5772\n",
      "Epoch 5/5\n",
      "\u001B[1m47/47\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9978 - loss: 0.0193 - val_accuracy: 0.7183 - val_loss: 1.8704\n",
      "\n",
      "Training with epochs = 10 and batch size = 10\n",
      "\n",
      "Epoch 1/10\n",
      "\u001B[1m140/140\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9974 - loss: 0.0228 - val_accuracy: 0.7167 - val_loss: 1.9646\n",
      "Epoch 2/10\n",
      "\u001B[1m140/140\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9935 - loss: 0.0390 - val_accuracy: 0.7183 - val_loss: 1.8847\n",
      "Epoch 3/10\n",
      "\u001B[1m140/140\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9942 - loss: 0.0364 - val_accuracy: 0.7267 - val_loss: 1.9187\n",
      "Epoch 4/10\n",
      "\u001B[1m140/140\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9907 - loss: 0.0406 - val_accuracy: 0.7500 - val_loss: 1.2777\n",
      "Epoch 5/10\n",
      "\u001B[1m140/140\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9914 - loss: 0.0516 - val_accuracy: 0.7550 - val_loss: 1.4923\n",
      "Epoch 6/10\n",
      "\u001B[1m140/140\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9939 - loss: 0.0381 - val_accuracy: 0.7433 - val_loss: 1.4006\n",
      "Epoch 7/10\n",
      "\u001B[1m140/140\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9958 - loss: 0.0301 - val_accuracy: 0.7167 - val_loss: 2.2429\n",
      "Epoch 8/10\n",
      "\u001B[1m140/140\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.9988 - loss: 0.0157 - val_accuracy: 0.7533 - val_loss: 1.6041\n",
      "Epoch 9/10\n",
      "\u001B[1m140/140\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.9924 - loss: 0.0468 - val_accuracy: 0.7517 - val_loss: 1.7065\n",
      "Epoch 10/10\n",
      "\u001B[1m140/140\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.9978 - loss: 0.0201 - val_accuracy: 0.7483 - val_loss: 1.9326\n",
      "\n",
      "Training with epochs = 10 and batch size = 20\n",
      "\n",
      "Epoch 1/10\n",
      "\u001B[1m70/70\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9975 - loss: 0.0200 - val_accuracy: 0.7500 - val_loss: 1.6754\n",
      "Epoch 2/10\n",
      "\u001B[1m70/70\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9968 - loss: 0.0197 - val_accuracy: 0.7550 - val_loss: 1.6978\n",
      "Epoch 3/10\n",
      "\u001B[1m70/70\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9963 - loss: 0.0249 - val_accuracy: 0.7517 - val_loss: 1.8236\n",
      "Epoch 4/10\n",
      "\u001B[1m70/70\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9966 - loss: 0.0306 - val_accuracy: 0.7383 - val_loss: 2.0310\n",
      "Epoch 5/10\n",
      "\u001B[1m70/70\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9926 - loss: 0.0425 - val_accuracy: 0.7333 - val_loss: 2.0419\n",
      "Epoch 6/10\n",
      "\u001B[1m70/70\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9952 - loss: 0.0360 - val_accuracy: 0.7400 - val_loss: 2.0007\n",
      "Epoch 7/10\n",
      "\u001B[1m70/70\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9975 - loss: 0.0159 - val_accuracy: 0.7300 - val_loss: 2.2557\n",
      "Epoch 8/10\n",
      "\u001B[1m70/70\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9982 - loss: 0.0177 - val_accuracy: 0.7217 - val_loss: 2.3196\n",
      "Epoch 9/10\n",
      "\u001B[1m70/70\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9925 - loss: 0.0605 - val_accuracy: 0.7250 - val_loss: 2.3773\n",
      "Epoch 10/10\n",
      "\u001B[1m70/70\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9975 - loss: 0.0213 - val_accuracy: 0.7050 - val_loss: 2.6993\n",
      "\n",
      "Training with epochs = 10 and batch size = 30\n",
      "\n",
      "Epoch 1/10\n",
      "\u001B[1m47/47\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.9990 - loss: 0.0132 - val_accuracy: 0.7050 - val_loss: 2.7406\n",
      "Epoch 2/10\n",
      "\u001B[1m47/47\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.9938 - loss: 0.0386 - val_accuracy: 0.7050 - val_loss: 2.6249\n",
      "Epoch 3/10\n",
      "\u001B[1m47/47\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.9967 - loss: 0.0255 - val_accuracy: 0.7033 - val_loss: 2.6690\n",
      "Epoch 4/10\n",
      "\u001B[1m47/47\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.9937 - loss: 0.0375 - val_accuracy: 0.7033 - val_loss: 2.7153\n",
      "Epoch 5/10\n",
      "\u001B[1m47/47\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9992 - loss: 0.0116 - val_accuracy: 0.7017 - val_loss: 2.7995\n",
      "Epoch 6/10\n",
      "\u001B[1m47/47\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9979 - loss: 0.0182 - val_accuracy: 0.7017 - val_loss: 2.8132\n",
      "Epoch 7/10\n",
      "\u001B[1m47/47\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9978 - loss: 0.0193 - val_accuracy: 0.7017 - val_loss: 2.8282\n",
      "Epoch 8/10\n",
      "\u001B[1m47/47\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.9894 - loss: 0.0627 - val_accuracy: 0.6967 - val_loss: 2.8454\n",
      "Epoch 9/10\n",
      "\u001B[1m47/47\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9961 - loss: 0.0234 - val_accuracy: 0.7000 - val_loss: 2.8640\n",
      "Epoch 10/10\n",
      "\u001B[1m47/47\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9942 - loss: 0.0338 - val_accuracy: 0.7000 - val_loss: 2.8605\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### ii. Train and Test Accuracies"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T12:44:38.194224Z",
     "start_time": "2024-07-24T12:44:38.192290Z"
    }
   },
   "source": [
    "print(f\"Best validation accuracy: {cnn_best_val_accuracy:.4f} when epochs = {cnn_best_epoch} and batch size = {cnn_best_batch_size}\")\n",
    "print(f\"with training accuracy: {cnn_best_accuracy:.4f}, training loss: {cnn_best_loss:.8f}, and validation loss: {cnn_best_val_loss:.4f}\")\n",
    "print(\"\")\n",
    "print(f\"When epochs = 2 and batch size = 10, validation accuracy: {cnn_original_val_accuracy:.4f}\")\n",
    "print(f\"with training accuracy: {cnn_original_accuracy:.4f}, training loss: {cnn_original_loss:.8f}, and validation loss: {cnn_original_val_loss:.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation accuracy: 0.7567 when epochs = 5 and batch size = 20\n",
      "with training accuracy: 0.9936, training loss: 0.06047726, and validation loss: 1.9220\n",
      "\n",
      "When epochs = 2 and batch size = 10, validation accuracy: 0.5517\n",
      "with training accuracy: 0.5014, training loss: 0.69963944, and validation loss: 0.6925\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T12:44:38.196856Z",
     "start_time": "2024-07-24T12:44:38.194807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if cnn_best_val_accuracy > cnn_original_val_accuracy:\n",
    "    print(f\"When comparing, the project guideline tells to use epochs = 2 and batch size = 10, but from the model training, it shows that using epochs = {cnn_best_epoch} and batch size = {cnn_best_batch_size} gives better fitted model for the classification.\")\n",
    "else:\n",
    "    print(\"It shows that using epoch = 2 and batch size = 10 as project guideline directed returns the highest validation accuracy, which means the best fitted model for classification.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When comparing, the project guideline tells to use epochs = 2 and batch size = 10, but from the model training, it shows that using epochs = 5 and batch size = 20 gives better fitted model for the classification.\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (f) Long Short-Term Memory Recurrent Neural Network"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### i. train LSTM recurrent neural network model\n",
    "The guideline asks to use epochs = 10~50, batch_size = 10, but I tried extra combination using extra batch size to find optimal epochs and batch size with better validation accuracy."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<font color='Cyan'>\n",
    "\n",
    "Reference [19] for LSTM <br>\n",
    "from tensorflow.keras.layers import LSTM <br>\n",
    " <br>\n",
    "Reference [20] for TensorFlow RNN Guide <br>\n",
    "https://www.tensorflow.org/guide/keras/working_with_rnns <br>\n",
    " <br>\n",
    "Reference [21] for Turing Concept of RNN and LSTM <br>\n",
    "https://www.turing.com/kb/recurrent-neural-networks-and-lstm <br>\n",
    " <br>\n",
    "Reference [22] for Aditi Mittal's Medium article <br>\n",
    "https://aditi-mittal.medium.com/understanding-rnn-and-lstm-f7cdf6dfc14e \n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T12:44:38.265961Z",
     "start_time": "2024-07-24T12:44:38.197409Z"
    }
   },
   "source": [
    "rnn_model = Sequential([\n",
    "    Input(shape=(L,)),\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, name='rnn_embedding'),\n",
    "    LSTM(256, activation='relu', return_sequences=True, name='rnn_LSTM1'),\n",
    "    Dropout(0.2),\n",
    "    LSTM(256, activation='relu', return_sequences=True, name='rnn_LSTM2'),\n",
    "    Dropout(0.2),\n",
    "    LSTM(256, activation='relu', name='rnn_LSTM3'),\n",
    "    Dropout(0.2),\n",
    "    Dense(256, activation='relu', name='rnn_relu1'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid', name='rnn_sigmoid')\n",
    "])"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Due to repeated nan value return for training loss using epoch 10~50, batch size = 10,\n",
    "#### which keeps outputting 0.5 for validation accuracy and nan value for validation loss,\n",
    "#### I would like to try higher batch size, which is 30 and 50, and learning rate = 0.001 (or smaller) to have training loss non-nan value."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T12:49:16.206907Z",
     "start_time": "2024-07-24T12:49:16.201960Z"
    }
   },
   "cell_type": "code",
   "source": "rnn_model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T12:49:16.244425Z",
     "start_time": "2024-07-24T12:49:16.236904Z"
    }
   },
   "cell_type": "code",
   "source": "rnn_model.summary()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_3\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ rnn_embedding (\u001B[38;5;33mEmbedding\u001B[0m)       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m737\u001B[0m, \u001B[38;5;34m32\u001B[0m)        │       \u001B[38;5;34m160,000\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rnn_LSTM1 (\u001B[38;5;33mLSTM\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m737\u001B[0m, \u001B[38;5;34m256\u001B[0m)       │       \u001B[38;5;34m295,936\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m737\u001B[0m, \u001B[38;5;34m256\u001B[0m)       │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rnn_LSTM2 (\u001B[38;5;33mLSTM\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m737\u001B[0m, \u001B[38;5;34m256\u001B[0m)       │       \u001B[38;5;34m525,312\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m737\u001B[0m, \u001B[38;5;34m256\u001B[0m)       │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rnn_LSTM3 (\u001B[38;5;33mLSTM\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m)            │       \u001B[38;5;34m525,312\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rnn_relu1 (\u001B[38;5;33mDense\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m)            │        \u001B[38;5;34m65,792\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rnn_sigmoid (\u001B[38;5;33mDense\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │           \u001B[38;5;34m257\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ rnn_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">737</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">160,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rnn_LSTM1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">737</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,936</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">737</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rnn_LSTM2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">737</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">737</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rnn_LSTM3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rnn_relu1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rnn_sigmoid (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m1,572,609\u001B[0m (6.00 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,572,609</span> (6.00 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m1,572,609\u001B[0m (6.00 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,572,609</span> (6.00 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T12:49:16.251970Z",
     "start_time": "2024-07-24T12:49:16.250057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rnn_epochs_list = [10]\n",
    "rnn_batch_sizes = [30, 50]\n",
    "\n",
    "rnn_original_accuracy = 0\n",
    "rnn_original_loss = 0\n",
    "rnn_original_val_loss =0\n",
    "rnn_original_val_accuracy = 0\n",
    "\n",
    "rnn_best_accuracy = 0\n",
    "rnn_best_loss = 0\n",
    "rnn_best_val_loss =0\n",
    "rnn_best_val_accuracy = 0\n",
    "\n",
    "rnn_best_epoch = 0\n",
    "rnn_best_batch_size = 0\n",
    "rnn_best_history = None"
   ],
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T13:37:17.748710Z",
     "start_time": "2024-07-24T12:49:16.265679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epochs in rnn_epochs_list:\n",
    "    for batch_size in rnn_batch_sizes:\n",
    "        print(\"\")\n",
    "        print(f\"Training with epochs = {epochs} and batch size = {batch_size}\")\n",
    "        print(\"\")\n",
    "        rnn_history = rnn_model.fit(seq_pad_train, labels_train, epochs=epochs, batch_size=batch_size, validation_data=(seq_pad_test, labels_test), verbose=1)\n",
    "        \n",
    "        accuracy = max(rnn_history.history['accuracy'])\n",
    "        loss = max(rnn_history.history['loss'])        \n",
    "        val_accuracy = max(rnn_history.history['val_accuracy'])\n",
    "        val_loss = max(rnn_history.history['val_loss'])\n",
    "        \n",
    "        if epochs == 10 and batch_size == 10:\n",
    "            rnn_original_accuracy = accuracy\n",
    "            rnn_original_loss = loss\n",
    "            rnn_original_val_accuracy = val_accuracy\n",
    "            rnn_original_val_loss = val_loss\n",
    "        \n",
    "        if val_accuracy > rnn_best_val_accuracy:\n",
    "            rnn_best_accuracy = accuracy\n",
    "            rnn_best_loss = loss\n",
    "            rnn_best_val_loss = val_loss\n",
    "            rnn_best_val_accuracy = val_accuracy\n",
    "            rnn_best_epoch = epochs\n",
    "            rnn_best_batch_size = batch_size\n",
    "            rnn_best_history = rnn_history"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with epochs = 10 and batch size = 30\n",
      "\n",
      "Epoch 1/10\n",
      "\u001B[1m47/47\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m162s\u001B[0m 3s/step - accuracy: 0.5064 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 2/10\n",
      "\u001B[1m47/47\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m156s\u001B[0m 3s/step - accuracy: 0.4899 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 3/10\n",
      "\u001B[1m47/47\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m150s\u001B[0m 3s/step - accuracy: 0.5001 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 4/10\n",
      "\u001B[1m47/47\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m148s\u001B[0m 3s/step - accuracy: 0.5113 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 5/10\n",
      "\u001B[1m47/47\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m142s\u001B[0m 3s/step - accuracy: 0.5013 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 6/10\n",
      "\u001B[1m47/47\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m153s\u001B[0m 3s/step - accuracy: 0.4774 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 7/10\n",
      "\u001B[1m47/47\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m150s\u001B[0m 3s/step - accuracy: 0.5019 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 8/10\n",
      "\u001B[1m47/47\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m153s\u001B[0m 3s/step - accuracy: 0.5122 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 9/10\n",
      "\u001B[1m47/47\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m153s\u001B[0m 3s/step - accuracy: 0.4964 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 10/10\n",
      "\u001B[1m47/47\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m150s\u001B[0m 3s/step - accuracy: 0.5021 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "\n",
      "Training with epochs = 10 and batch size = 50\n",
      "\n",
      "Epoch 1/10\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m134s\u001B[0m 5s/step - accuracy: 0.4913 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 2/10\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m142s\u001B[0m 5s/step - accuracy: 0.4998 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 3/10\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m136s\u001B[0m 5s/step - accuracy: 0.4901 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 4/10\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m138s\u001B[0m 5s/step - accuracy: 0.4796 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 5/10\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m141s\u001B[0m 5s/step - accuracy: 0.4937 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 6/10\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m136s\u001B[0m 5s/step - accuracy: 0.5254 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 7/10\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m143s\u001B[0m 5s/step - accuracy: 0.4871 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 8/10\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m135s\u001B[0m 5s/step - accuracy: 0.5033 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 9/10\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m132s\u001B[0m 5s/step - accuracy: 0.5300 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n",
      "Epoch 10/10\n",
      "\u001B[1m28/28\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m127s\u001B[0m 5s/step - accuracy: 0.5076 - loss: nan - val_accuracy: 0.5000 - val_loss: nan\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ii. Train and Test Accuracies"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T17:46:41.574334Z",
     "start_time": "2024-07-24T17:46:41.571738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Validation accuracy: {rnn_best_val_accuracy:.4f} when epochs = {rnn_best_epoch} and batch size = {rnn_best_batch_size} with training accuracy: {rnn_best_accuracy:.4f}, training loss: {rnn_best_loss:.8f}, and validation loss: {rnn_best_val_loss:.4f}\")\n",
    "print(\"\")\n",
    "print(\"Training loss still remains to be nan, which results that validation accuracy to be remain as 0.5. There possibly be several reasons.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.5000 when epochs = 10 and batch size = 30 with training accuracy: 0.5000, training loss: nan, and validation loss: nan\n",
      "\n",
      "Training loss still remains to be nan, which results that validation accuracy to be remain as 0.5. There possibly be several reasons.\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1.\tLearning Rate Too High: If the learning rate is too high, the model’s weights might diverge, leading to NaN values. <br>\n",
    " ⇒ Need to reduce the learning rate. <br>\n",
    "2.\tData Issues: There might be NaN or infinite values or too many zero values in input data. <br>\n",
    " ⇒ Need to ensure the data is clean and preprocessed correctly. <br>\n",
    "3. Gradient Explosion: Large gradients can cause weights to update to NaN values. <br>\n",
    " ⇒ Need to use gradient clipping to cap the gradients during backpropagation. <br>\n",
    "4. Batch Size: Very small or very large batch sizes can sometimes cause instability in training. <br>\n",
    " ⇒ Need different batch sizes. <br>\n",
    "\n",
    "And I assume that the most significant affect for training loss having nan value is because of the zero values in input data generated when padding or truncating each text for pre-processing. <br>\n",
    "Therefore, we might need different way to handle data to resolve the problem, such as using the lower percentile for review length (L) like 30% instead of 70% to have less zero values in input data."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### (EXTRA) Model Comparison by validation accuracy rate"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T18:08:40.203556Z",
     "start_time": "2024-07-24T18:08:40.199918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if rnn_best_val_accuracy > cnn_best_val_accuracy > mlp_best_val_accuracy:\n",
    "    print(f\"When comparing three models, MLP NN, 1-D CNN, and LSTM RNN, LSTM RNN model showed highest validation accuracy = {rnn_best_val_accuracy:.4f} followed by 1-D CNN model validation accuracy = {cnn_best_val_accuracy:.4f}. And MLP NN model had lowest validation accuracy = {mlp_best_val_accuracy:.4f}. Therefore, select LSTM RNN model.\")\n",
    "elif rnn_best_val_accuracy > mlp_best_val_accuracy > cnn_best_val_accuracy:\n",
    "    print(f\"When comparing three models, MLP NN, 1-D CNN, and LSTM RNN, LSTM RNN model showed highest validation accuracy = {rnn_best_val_accuracy:.4f} followed by MLP NN model validation accuracy = {mlp_best_val_accuracy:.4f}. And 1-D CNN model had lowest validation accuracy = {cnn_best_val_accuracy:.4f}. Therefore, select LSTM RNN model.\")\n",
    "elif cnn_best_val_accuracy > rnn_best_val_accuracy > mlp_best_val_accuracy:\n",
    "    print(f\"When comparing three models, MLP NN, 1-D CNN, and LSTM RNN, 1-D CNN model showed highest validation accuracy = {cnn_best_val_accuracy:.4f} followed by LSTM RNN model validation accuracy = {rnn_best_val_accuracy:.4f}. And MLP NN model had lowest validation accuracy = {mlp_best_val_accuracy:.4f}. Therefore, select 1-D CNN model.\")\n",
    "elif cnn_best_val_accuracy > mlp_best_val_accuracy > rnn_best_val_accuracy:\n",
    "    print(f\"When comparing three models, MLP NN, 1-D CNN, and LSTM RNN, 1-D CNN model showed highest validation accuracy = {cnn_best_val_accuracy:.4f} followed by MLP NN model validation accuracy = {mlp_best_val_accuracy:.4f}. And LSTM RNN model had lowest validation accuracy = {rnn_best_val_accuracy:.4f}. Therefore, select 1-D CNN model.\")\n",
    "elif mlp_best_val_accuracy > rnn_best_val_accuracy > cnn_best_val_accuracy:\n",
    "    print(f\"When comparing three models, MLP NN, 1-D CNN, and LSTM RNN, MLP NN model showed highest validation accuracy = {mlp_best_val_accuracy:.4f} followed by LSTM RNN model validation accuracy = {rnn_best_val_accuracy:.4f}. And 1-D CNN model had lowest validation accuracy = {cnn_best_val_accuracy:.4f}. Therefore, select MLP NN model.\")\n",
    "elif mlp_best_val_accuracy > cnn_best_val_accuracy > rnn_best_val_accuracy:\n",
    "    print(f\"When comparing three models, MLP NN, 1-D CNN, and LSTM RNN, MLP NN model showed highest validation accuracy = {mlp_best_val_accuracy:.4f} followed by 1-D CNN model validation accuracy = {cnn_best_val_accuracy:.4f}. And LSTM RNN model had lowest validation accuracy = {rnn_best_val_accuracy:.4f}. Therefore, select MLP NN model.\")\n",
    "else:\n",
    "    print(f\"Two or All models have same validation accuracy that MLP NN model validation accuracy = {mlp_best_val_accuracy:.4f}, 1-D CNN model validation accuracy = {cnn_best_val_accuracy:.4f}, and LSTM RNN model validation accuracy = {rnn_best_val_accuracy:.4f}. Therefore, select any model with highest validation accuracy.\")    "
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When comparing three models, MLP NN, 1-D CNN, and LSTM RNN, 1-D CNN model showed highest validation accuracy = 0.7567 followed by MLP NN model validation accuracy = 0.6200. And LSTM RNN model had lowest validation accuracy = 0.5000. Therefore, select 1-D CNN model.\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "552FP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
